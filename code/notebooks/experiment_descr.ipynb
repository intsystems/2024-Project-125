{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "36fee900-0c2e-4222-a508-dd1f8b4b9063",
   "metadata": {},
   "source": [
    "### Эксперимент"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4c3cd5-42cd-41a5-9555-de30427cb473",
   "metadata": {},
   "source": [
    "#### Фиксированные параметры генератора\n",
    "- series_type = \"default\"  // обычная линейная регрессия\n",
    "\n",
    "- dim=10 // размерность сигнала\n",
    "- low=-10, high=10 // границы весов для получения отклика\n",
    "- noise_var=1 // дисперсия нормального шума\n",
    "- workers_num=3 // число различных генераторов\n",
    "- lower_bound=100, upper_bound=400 // границы длин каждого из кусков, получаемых генератором\n",
    "- alternating=True // нет двух подряд кусков одного типа\n",
    "#### Фиксированные параметры алгоритма\n",
    "- from_start=False // начинаем подсчет всех потерь (и составного эксперта) не с самого начала, а после того как прошли по одному разу учатки каждого из  генераторов\n",
    "\n",
    "- length=1500 // длина изучаемого участка временного ряда\n",
    "\n",
    "- a=-40, b=40 // параметры алгоритма, отклики отсеиваем тоже по ним\n",
    "\n",
    "#### Гиперпараметры эксперимента\n",
    "- windows = [5, 10, 20] // варьируем длину окна обучения ($\\frac12x, 1x, 2x$ соответственно, где $x$  &mdash; dim  сигнала )\n",
    "- weights_function // функция начальных весов, cравниваем $\\dfrac1{x^\\alpha}$ для разных $\\alpha$ и дефолтную $\\dfrac{1}{(x+1)\\ln^2(x+1)}$\n",
    "- alpha_function // функция коэффицента $\\alpha$ в Mixing Update, cравниваем $\\dfrac1{(1 + x)^\\alpha}$ для разных $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ac7ec9-1085-4058-a7b5-eb6107eac55a",
   "metadata": {},
   "source": [
    "#### Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1da3fd1-fc63-4694-853f-81d68e5bb7a9",
   "metadata": {},
   "source": [
    "##### Train window\n",
    "В среднем, при окне обучения равном dim=10, результаты оказались лучше чем для размеров 5 и 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f4a2a3-42b2-4538-87f6-e748170367e8",
   "metadata": {},
   "source": [
    "##### Weights function\n",
    "При всех рассмотренных окнах, регрет для функции весов $\\dfrac1{x^\\alpha}$ меньше, чем для дефолтной $\\dfrac{1}{(x+1)\\ln^2(x+1)}$, и при стремлении $\\alpha$ к 1 регрет уменьшается. То есть минимальный регрет среди рассмотренных здесь достигается  для $\\dfrac1{x^{1.05}}$, она же была мной зафиксирована для экспериментами над alpha_function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ff9ecd-f499-43e3-8622-c2c2098b4c09",
   "metadata": {},
   "source": [
    "##### Alpha function\n",
    "При окнах обучения $5$ и $10$, побеждают $\\dfrac1{(x+1)^{1.5}}$ и $\\dfrac1{(x+1)^{1.3}}$, но отрыв от остальных не слишком велик. \\\n",
    "При окне $20$ побеждает дефолтная $\\dfrac1{(x+1)}$ c нарастающим отрывом при увеличении $\\alpha$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b86e7f7-9da1-4ed8-98fc-e1f8e947f695",
   "metadata": {},
   "source": [
    "**Таким образом, на практике лучшей функцией для начальных весов является $\\dfrac1{x^{1+\\varepsilon}}$ c как можно меньшим $\\varepsilon$**\n",
    "\n",
    "**Значительных улучшений дефолтной функции $\\dfrac1{(x+1)}$ для коэффицента $\\alpha$ Mixing Update  пока нет**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049beedc-60ef-4e9c-8c41-959dbdc8781b",
   "metadata": {},
   "source": [
    "Теоретическая оценка сверху выглядит нормально:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
