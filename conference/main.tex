\documentclass{icorsdssv2024}
\begin{document}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%          BELOW THIS LINE YOU CAN MODIFY WITH YOUR DATA          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Title and running title (short title) to be used as header
\mytitle{Influence of hyperparameters on online aggregation with countable experts}
\mytitlerunning{Online experts aggregation}

% Authors and running list of authors to be used as header
% Author names must be included as: "N. Surname"
% Author names for running titles must be specified as:
% For one author: N. Surname
% For two authors: N1. Surname1 and N2. Surname2
% For more than two authors: N1. Surname \emph{et al.}
% Use \underline for the presenter.

\myauthor{S.\,M.~Kunin-Bogoiavlenskii$^{1\ast}$, A.\,V.~Zukhba$^1$, R.\,D.~Zukhba$^1$}
\myauthorrunning{S.\,M.~Kunin-Bogoiavlenskii \emph{et al.}}

% Full address for correspondence and e-mail of all authors
\myaddress{$^1$Moscow Insitute of Physics and Technology
\\ kunin-bogoiavlenskii.sm@phystech.edu; a\_\_l@mail.ru; zukhba.rd@phystech.edu \\ $^{*}$Presenting author}
\abstract{
Aggregating forecasts from multiple experts is a valuable method to improve prediction accuracy.
    Our work examines the influence of hyperparameters on the accuracy of the aggregation algorithm for a countable number of experts.
    We implement a time series generator with specified properties and an aggregating forecasting model. 
    We conduct a series of experiments with various hyperparameters of the algorithm (including initialization weights, mixing scheme, train window). 
    The experiments confirm that these hyperparameters have a significant influence on the algorithm's performance. }
% Keywords (at most 5)
\mykeywords{online learning; aggregating algorithm; prediction with expertsâ€™ advice; Fixed Share, Mixing Past Posteriors (MPP)}

\mymaketitle

Our work focuses on the problem of online time series forecasting using expert advice, particularly when dealing with a countable number of experts. This means that the pool of potential experts is not fixed beforehand, but rather new experts can be introduced dynamically over time.
Inspired by the algorithm developed in \cite{article}, which tackles online prediction with countable experts, we investigate the critical role of hyperparameter optimization in achieving optimal performance. Our approach makes no assumptions about the underlying nature of the data, allowing it to handle deterministic, stochastic, or other types of time series.

The standard online learning framework for prediction with expert advice involves a master algorithm aggregating predictions from a set of expert models. At each time step, the master algorithm combines expert predictions, makes its own prediction, and then receives feedback in the form of a loss function. The goal is to minimize the difference between the master's cumulative loss and the best expert's cumulative loss, a metric known as regret.
Traditional algorithms like Fixed Share \cite{article98} and Mixing Past Posteriors (MPP) \cite{article02} assume a fixed set of experts. However, in many real-world scenarios, the set of experts can expand dynamically. This necessitates algorithms that can handle countable expert sets, like the GMPP algorithm proposed in \cite{article}, where new experts can be introduced at each time step. 
%
%The dynamic nature of countable expert sets introduces complexities in hyperparameter tuning. The algorithm needs to effectively incorporate predictions from newly introduced experts while leveraging the performance history of existing experts. Key challenges include:
%Determining how to initialize the weights of new experts relative to existing ones.
%Choosing the best mixing scheme for combining past and current expert predictions.
%Deciding on the appropriate training window size for individual experts.
%This paper addresses these challenges by conducting a comprehensive experimental study, analyzing the impact of various hyperparameters on the GMPP algorithm's performance. We use a synthetic time series generator to control the underlying data dynamics and evaluate different hyperparameter configurations.
%Through our experimental analysis, we aim to provide valuable insights into the optimal hyperparameter settings for the GMPP algorithm, enabling its successful application in real-world time series forecasting tasks with countable expert sets. Our findings contribute to a deeper understanding of the intricacies of online aggregation with countable experts and pave the way for more robust and adaptable forecasting solutions.

%This work is based on an algorithm from \cite{article}, focusing on online prediction games with expert advice. The data is a time series of outcome pairs, <<signal>> and <<response>>, with no assumptions about its nature. Machine learning methods are used within a game-theoretic approach to build forecasters. An online learning master model combines predictions from reference forecasters, or experts.
%
%The general prediction algorithm with expert advice involves learning in trials at discrete time points. Experts provide predictions based on past data, the master model makes a decision using an aggregating algorithm, and the true outcome is revealed, scoring both master and expert models using a loss function. The difference between the master's and expert's cumulative losses is defined as regret, with the goal being to minimize it.
%
%Special assumptions about the data generation structure are used when building forecasting strategies. Multiple generators produce segments of the time series, which are merged. These segments, or areas of stationarity, can be studied using machine learning methods. The series of prediction steps is divided into segments that frame arbitrary sequences of expert strategies, called a partition. The modified goal of the aggregating algorithm is to perform well relative to the best partition.
%
%The Fixed Share algorithm \cite{article98} and its generalization, the Mixing Past Posteriors (MPP) method \cite{article02}, are used. The cumulative losses of the aggregating algorithm are related to convex combinations of expert losses, changing the concept of regret. The algorithm's cumulative losses are compared to the cumulative losses of convex combinations of expert strategies.
%
%Unlike \cite{article98, article02}, there is no predefined set of competing expert strategies. New expert strategies are constructed at each step of the online learning process, with the master aggregating the forecasts of all expert strategies in real-time. The Algorithm GMPP from \cite{article} is the basis of our experiments.

This paper explores how key hyperparameters affect the GMPP algorithm's performance. We use a synthetic time series generator with specific properties to conduct an experimental study, which helps us control the underlying data dynamics and evaluate the impact of different hyperparameter configurations.

Our goal is to provide useful insights into the best hyperparameter settings for the GMPP algorithm, making it easier to use in real-world time series forecasting tasks with countable expert sets. We emphasize the importance of hyperparameter optimization for achieving optimal performance and contribute to a better understanding of online aggregation with countable experts. This work helps pave the way for more robust and adaptable forecasting solutions.






%%\noindent
%In this formulation of the forecasting problem, the series of prediction steps is divided into segments that frame arbitrary sequences of expert strategies. 
%The sequence of segments and its associated sequence of experts is called a partition. 
%The modified goal of the aggregating algorithm is to perform well relative to the best partition. 
%Accordingly, the new concept of algorithm regret is the difference between the algorithm's losses and the cumulative losses of the sequence of experts. 
%This change allows for a more accurate modeling of real-life conditions, where the nature of responses may change over time and different experts may predict with varying degrees of success depending on the current trend. 
%
%%\noindent
%The corresponding algorithm is called Fixed Share \cite{article98}. 
%A further proposed generalization of it is the Mixing Past Posteriors (MPP) method \cite{article02}. 
%The cumulative losses of the aggregating algorithm are related to convex combinations of expert losses. 
%The concept of regret also changes. 
%Now the algorithm's cumulative losses are compared to the cumulative losses of convex combinations of expert strategies.
%
%A characteristic feature of the problem considered in \cite{article} is the absence of a predefined set of competing expert strategies, as was the case in the works cited above.
%Instead, new expert strategies are constructed at each step of the online learning process.
%The master must aggregate the forecasts of all expert strategies constructed up to that time in real-time at each step. 
%Algorithm GMPP, proposed in \cite{article}, is the foundation of our experiments. 
%
%This paper investigates the influence of key hyperparameters on the performance of the GMPP algorithm. We conduct an experimental study using a synthetic time series generator with specific properties, allowing us to control the underlying data dynamics and assess the impact of various hyperparameter configurations. 
%Through our experimental study, we aim to provide valuable insights into the optimal hyperparameter settings for the GMPP algorithm, facilitating its effective deployment in real-world time series forecasting tasks with countable expert sets.
%By highlighting the crucial role of hyperparameter optimization in achieving optimal performance, we contribute to a deeper understanding of the intricacies of online aggregation with countable experts and pave the way for more robust and adaptable forecasting solutions.

\bibliographystyle{unsrt}
\bibliography{ref}

\end{document}
